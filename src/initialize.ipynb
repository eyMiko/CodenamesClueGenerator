{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialize.ipynb: Run this file once to initialize the program directory.\n",
    "#### It will:\n",
    "####   - Install the necessary python modules\n",
    "####   - Load in the FastText model and save to a file for faster load in future --> ../data/fasttext_vectors.kv\n",
    "####   - Create a similarity matrix for hint words --> ../data/similarity_matrix.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/miko/anaconda3/envs/nlp/lib/python3.9/site-packages (4.64.0)\n",
      "Requirement already satisfied: nltk in /home/miko/anaconda3/envs/nlp/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/miko/anaconda3/envs/nlp/lib/python3.9/site-packages (from nltk) (2022.4.24)\n",
      "Requirement already satisfied: joblib in /home/miko/anaconda3/envs/nlp/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in /home/miko/anaconda3/envs/nlp/lib/python3.9/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /home/miko/anaconda3/envs/nlp/lib/python3.9/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: ipynb in /home/miko/anaconda3/envs/nlp/lib/python3.9/site-packages (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "## Installs\n",
    "\n",
    "!pip install tqdm\n",
    "!pip install nltk\n",
    "!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download FastText model and save to file (Runtime: ~6 mins)\n",
    "import gensim.downloader\n",
    "\n",
    "fasttext = gensim.downloader.load('fasttext-wiki-news-subwords-300')\n",
    "fasttext.save('../data/fasttext_vectors.kv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading FastText model\n",
    "fasttext = KeyedVectors.load('../data/fasttext_vectors.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String paths to necessary files\n",
    "CODENAME_WORDS_FILE = '../data/codename_words.txt'\n",
    "HINT_WORDS_FILE = '../data/hint_words.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x,y):\n",
    "# Calculates cosine similarity of two word vectors via a normalized dot product \n",
    "    dp = np.dot(x,y) / (norm(x)*norm(y))\n",
    "    return dp\n",
    "\n",
    "def create_sim_mat(fasttext, hint_words, game_words):\n",
    "# Stores the similarities of hint/game word combinations in a .csv file\n",
    "\n",
    "    # Create a pandas df to store similarities of each game word/hint word pair\n",
    "    data = pd.DataFrame(np.zeros((len(hint_words), len(game_words))))\n",
    "\n",
    "    # For each hint word\n",
    "    for i in tqdm(range(len(hint_words))):\n",
    "\n",
    "        # Find fasttext word vector for hint word\n",
    "        hwv = fasttext[hint_words[i]]\n",
    "\n",
    "        # For each game word\n",
    "        for j in range(len(game_words)):\n",
    "\n",
    "            # Find fasttext word vector for hint word\n",
    "            gwv = fasttext[game_words[j]]\n",
    "\n",
    "            # Calculate and store cos similarity of game word and hint word\n",
    "            data.iloc[i, j] = cosine_similarity(gwv, hwv)\n",
    "\n",
    "    print(data.head())\n",
    "    \n",
    "    # Save dataframe to .csv file\n",
    "    data.index = hint_words\n",
    "    data.columns = game_words\n",
    "    data.index = data.index.str.lower()\n",
    "    data.columns = data.columns.str.lower()\n",
    "    data.to_csv('../data/similarity_matrix.csv')\n",
    "    \n",
    "def load_hint_words():\n",
    "# Returns a list of hint words read from csv file\n",
    "# Note: Later change this to the list of words in fasttext\n",
    "    hint_words = pd.read_csv(HINT_WORDS_FILE, index_col=0).hints.tolist()\n",
    "    hint_words = remove_unseen_words(hint_words)\n",
    "    return hint_words\n",
    "\n",
    "\n",
    "def load_codename_words():\n",
    "# Returns a list of words from codenames \n",
    "# Turns words lower case and removes spaces from compound words\n",
    "# Removes a word from the game if it's not in fasttext model\n",
    "    with open(CODENAME_WORDS_FILE, 'r') as f:\n",
    "        uppercase_words = f.readlines()\n",
    "\n",
    "    # Turn words lower case and remove spaces from compound words\n",
    "    game_words = [w.lower().strip().replace(\" \", \"\") for w in uppercase_words]\n",
    "    \n",
    "    # Removes a word from game if it has no corresponding fasttext word vector\n",
    "    game_words = remove_unseen_words(game_words)\n",
    "    \n",
    "    # Return a list of game words\n",
    "    return game_words\n",
    "\n",
    "def remove_unseen_words(inlist):\n",
    "# Removes words from list that are not found in fasttext model\n",
    "# Returns a \"cleaned\" copy of list\n",
    "# Note: original list passed in remains unaltered\n",
    "    outlist = []\n",
    "    for w in inlist:\n",
    "        if w in fasttext.key_to_index:\n",
    "            outlist.append(w)\n",
    "        else:\n",
    "            print(\"[remove_unseen_words] OUTPUT: %s not found in fasttext -> excluded from words list\"%w)\n",
    "            continue\n",
    "    return outlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[remove_unseen_words] OUTPUT: pdas not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: zus not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: anaheim not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: mpegs not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: greensboro not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: usps not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: mrna not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: cdna not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: liechtenstein not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: swaziland not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: lochness not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: scubadiver not found in fasttext -> excluded from words list\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b364d59f0e254991900ea2702ab654b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8792 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0  0.153206  0.401138  0.412929  0.435460  0.200337  0.286954  0.336101   \n",
      "1  0.250982  0.417320  0.452736  0.349176  0.279125  0.278332  0.456900   \n",
      "2  0.279441  0.306340  0.328569  0.211479  0.232448  0.314945  0.303217   \n",
      "3  0.236877  0.383886  0.367366  0.271110  0.271447  0.372658  0.333384   \n",
      "4  0.218201  0.415096  0.479813  0.386711  0.179930  0.321156  0.319677   \n",
      "\n",
      "        7         8         9    ...       388       389       390       391  \\\n",
      "0  0.262615  0.333116  0.204481  ...  0.374421  0.454222  0.436431  0.417956   \n",
      "1  0.340666  0.323183  0.243550  ...  0.430588  0.369529  0.467984  0.436817   \n",
      "2  0.321691  0.289576  0.238147  ...  0.330261  0.359034  0.568196  0.396002   \n",
      "3  0.294110  0.250428  0.204447  ...  0.344032  0.363700  0.521332  0.322617   \n",
      "4  0.330052  0.306445  0.250183  ...  0.428534  0.368750  0.391434  0.442201   \n",
      "\n",
      "        392       393       394       395       396       397  \n",
      "0  0.285503  0.313824  0.360846  0.395158  0.288040  0.320861  \n",
      "1  0.311715  0.280682  0.385873  0.357004  0.273329  0.547863  \n",
      "2  0.319767  0.263546  0.265932  0.337733  0.271595  0.318437  \n",
      "3  0.300489  0.253979  0.334921  0.366475  0.296535  0.276901  \n",
      "4  0.257683  0.358578  0.384322  0.366068  0.326753  0.272193  \n",
      "\n",
      "[5 rows x 398 columns]\n"
     ]
    }
   ],
   "source": [
    "## Create similarity matrix and save to file (Runtime: ~18 mins)\n",
    "\n",
    "# Load the hint words and the game (codenames) words\n",
    "hint_words = load_hint_words()\n",
    "game_words = load_codename_words()\n",
    "\n",
    "# Store similarity scores of hint/game words in .csv file\n",
    "create_sim_mat(fasttext, hint_words, game_words)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

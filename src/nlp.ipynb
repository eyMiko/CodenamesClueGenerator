{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Codenames Clues using FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Installs\n",
    "\n",
    "# !pip install tqdm\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import \n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ** Run once to download FastText model\n",
    "\n",
    "# fasttext = gensim.downloader.load('fasttext-wiki-news-subwords-300')\n",
    "# fasttext.save('../data/fasttext_vectors.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999999\n",
      "<class 'gensim.models.keyedvectors.KeyedVectors'>\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "## Initialize \n",
    "\n",
    "# Initialize stemmers for word similarity\n",
    "porter = PorterStemmer()\n",
    "lancaster=LancasterStemmer()\n",
    "\n",
    "# Load fastText vectors\n",
    "fasttext = KeyedVectors.load('../data/fasttext_vectors.kv')\n",
    "\n",
    "# print(len(fasttext))\n",
    "# print(type(fasttext))\n",
    "# print(len(fasttext[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "\n",
    "CODENAME_WORDS_FILE = '../data/codename_words.txt'\n",
    "HINT_WORDS_FILE = '../data/hint_words.csv'\n",
    "SUBSTR_LEN = 4\n",
    "\n",
    "# # Modifiers for Clue Quality Metric (not used in this implementation)\n",
    "# team_score_modifier = 10\n",
    "# enemy_score_modifier = -5\n",
    "# neutral_score_modifier = -1\n",
    "# double_agent_score_modifier = -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utility Functions\n",
    "\n",
    "def cosine_similarity(x,y):\n",
    "# Calculates cosine similarity of two word vectors\n",
    "# via a normalized dot product \n",
    "    dp = np.dot(x,y) / (norm(x)*norm(y))\n",
    "    return dp\n",
    "\n",
    "\n",
    "def get_example_board(codenames_words):\n",
    "# Returns a list of lists representing game board\n",
    "# [[team_words], [enemy_words], [neutral_words], [double_agent_word]]\n",
    "    words = codenames_words.copy()\n",
    "    shuffle(words)\n",
    "    return [\n",
    "        words[0:9], #team words - 9\n",
    "        words[9:17], #enemy words - 8\n",
    "        words[17:24], #neutral words - 7\n",
    "        [words[24]] #double agent word - 1\n",
    "    ]\n",
    "\n",
    "\n",
    "def load_hint_words():\n",
    "# Returns a list of hint words read from csv file\n",
    "# Note: Later change this to the list of words in fasttext\n",
    "    hint_words = pd.read_csv(HINT_WORDS_FILE, index_col=0).hints.tolist()\n",
    "    hint_words = remove_unseen_words(hint_words)\n",
    "    return hint_words\n",
    "\n",
    "\n",
    "def load_codename_words():\n",
    "# Returns a list of words from codenames \n",
    "# Turns words lower case and removes spaces from compound words\n",
    "# Removes a word from the game if it's not in fasttext model\n",
    "    with open(CODENAME_WORDS_FILE, 'r') as f:\n",
    "        uppercase_words = f.readlines()\n",
    "\n",
    "    # Turn words lower case and remove spaces from compound words\n",
    "    game_words = [w.lower().strip().replace(\" \", \"\") for w in uppercase_words]\n",
    "    \n",
    "    # Removes a word from game if it has no corresponding fasttext word vector\n",
    "    game_words = remove_unseen_words(game_words)\n",
    "    \n",
    "    # Return a list of game words\n",
    "    return game_words\n",
    "\n",
    "\n",
    "def remove_unseen_words(inlist):\n",
    "# Removes words from list that are not found in fasttext model\n",
    "# Returns a \"cleaned\" copy of list\n",
    "# Note: original list passed in remains unaltered\n",
    "    outlist = []\n",
    "    for w in inlist:\n",
    "        if w in fasttext.key_to_index:\n",
    "            outlist.append(w)\n",
    "        else:\n",
    "            print(\"[remove_unseen_words] OUTPUT: %s not found in fasttext -> excluded from words list\"%w)\n",
    "            continue\n",
    "    return outlist\n",
    "\n",
    "\n",
    "def long_comm_substr(s1, s2):\n",
    "# Returns the length of the longest common substring of two strings\n",
    "    res = 0;\n",
    "    for a in range(len(s1)):\n",
    "        for b in range(len(s2)):\n",
    "            k = 0;\n",
    "            while (a+k) < len(s1) and (b+k)<len(s2) and s1[a+k]==s2[b+k]:\n",
    "                k = k + 1;\n",
    "            res = max(res, k);\n",
    "    return res\n",
    "\n",
    "\n",
    "def are_similar(w1, w2):\n",
    "# Returns true if two words are \"similar\"\n",
    "# Two words are similar if they have the same stem, share a common substr, or if one contains the other\n",
    "# Porter stemming and Lancaster stemming are used via NLTK package\n",
    "    if w1.__contains__(w2) or w2.__contains__(w1):\n",
    "        print(\"[are_similar] OUTPUT: %s and %s are similar: one contains the other\"%(w1,w2))\n",
    "        return True\n",
    "    elif porter.stem(w1) == porter.stem(w2):\n",
    "        print(\"[are_similar] OUTPUT: %s and %s are similar: Porter Stemmer\"%(w1,w2))\n",
    "        return True\n",
    "    elif lancaster.stem(w1) == lancaster.stem(w2):\n",
    "        print(\"[are_similar] OUTPUT: %s and %s are similar: Lancaster Stemmer\"%(w1,w2))\n",
    "        return True\n",
    "    elif long_comm_substr(w1,w2) >= SUBSTR_LEN:\n",
    "        print(\"[are_similar] OUTPUT: %s and %s are similar: longest common substring too long\"%(w1,w2))\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main functions\n",
    "\n",
    "def create_sim_mat(hint_words, game_words):\n",
    "# Stores the similarities of hint/game word combinations in a .csv file\n",
    "\n",
    "    # Create a pandas df to store similarities of each game word/hint word pair\n",
    "    data = pd.DataFrame(np.zeros((len(hint_words), len(game_words))))\n",
    "\n",
    "    # For each hint word\n",
    "    for i in tqdm(range(len(hint_words))):\n",
    "\n",
    "        # Find fasttext word vector for hint word\n",
    "        hwv = fasttext[hint_words[i]]\n",
    "\n",
    "        # For each game word\n",
    "        for j in range(len(game_words)):\n",
    "\n",
    "            # Find fasttext word vector for hint word\n",
    "            gwv = fasttext[game_words[j]]\n",
    "\n",
    "            # Calculate and store cos similarity of game word and hint word\n",
    "            data.iloc[i, j] = cosine_similarity(gwv, hwv)\n",
    "\n",
    "    print(data.head())\n",
    "    \n",
    "    # Save dataframe to .csv file\n",
    "    data.index = hint_words\n",
    "    data.columns = game_words\n",
    "    data.index = data.index.str.lower()\n",
    "    data.columns = data.columns.str.lower()\n",
    "    data.to_csv('../data/similarity_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ** Run this cell only once ** \n",
    "# ## Create similarity matrix\n",
    "\n",
    "# # Load the hint words and the game (codenames) words\n",
    "# hint_words = load_hint_words()\n",
    "# game_words = load_codename_words()\n",
    "\n",
    "# # Store similarity scores of hint/game words in .csv file\n",
    "# create_sim_mat(hint_words, game_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. for every hint word, find the most similar game words.\n",
    "# 2. score the hint word based on which game words are most similar \n",
    "    # (our color is most similar, enemy color/assassin are most dissimilar)\n",
    "# 3. return the word based on the best score\n",
    "\n",
    "def hint_giver(sim_mat, board):\n",
    "    \n",
    "    # Unpack board info into separate lists\n",
    "    team_words, enemy_words, neutral_words, double_agent_word = board\n",
    "    \n",
    "    # Get a list of all game words\n",
    "    board_words = team_words + enemy_words + neutral_words + double_agent_word\n",
    "    \n",
    "    # Keep track of \"best\" hint words\n",
    "    best_score = 0\n",
    "    best_words = []\n",
    "    best_corr_words = []\n",
    "    \n",
    "    # Get a similarity matrix for hint words x board words\n",
    "    game_similarity = sim_mat.loc[:, board_words]\n",
    "    \n",
    "    \n",
    "    # For each row (hint)\n",
    "    for row in game_similarity.iterrows():\n",
    "        \n",
    "        # Get hint word\n",
    "        hint = row[0]\n",
    "        \n",
    "#         # If hint is too similar to any word on board, disregard it\n",
    "#         for board_word in board_words:\n",
    "#             if are_similar(hint, board_word):\n",
    "#                 print(\"Not yet implemented\")\n",
    "\n",
    "        # Add thresholding to make better hints\n",
    "        \n",
    "        # Sort similarity scores for this hint (for each game word)\n",
    "        df = row[1].sort_values(ascending=False)\n",
    "        \n",
    "        # Store score for this hint\n",
    "        score = 0\n",
    "        corr_words = []\n",
    "\n",
    "        # For each game word, in descending order of highest similarity\n",
    "        for game_word in df.index.tolist():\n",
    "            # If word belongs to team, increase score of this hint\n",
    "            if game_word in team_words:\n",
    "                score += 1\n",
    "                corr_words.append(game_word)\n",
    "                continue\n",
    "            # If word does not belong to team, stop increasing score for this hint\n",
    "            break\n",
    "\n",
    "        # Update best score\n",
    "        if best_score < score: \n",
    "            best_score = score\n",
    "            best_words = [hint]\n",
    "            best_corr_words = [corr_words]\n",
    "        elif best_score == score: # add if tied\n",
    "            best_words.append(hint)\n",
    "            best_corr_words.append(corr_words)\n",
    "    \n",
    "        # Implement some kind of tie breaker\n",
    "        # ...\n",
    "        \n",
    "    return best_words, best_score, best_corr_words\n",
    "\n",
    "\n",
    "# for integration: output as (hintword, hintnumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8781, 398)\n",
      "[remove_unseen_words] OUTPUT: pdas not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: zus not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: anaheim not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: mpegs not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: greensboro not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: usps not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: mrna not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: cdna not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: liechtenstein not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: swaziland not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: lochness not found in fasttext -> excluded from words list\n",
      "[remove_unseen_words] OUTPUT: scubadiver not found in fasttext -> excluded from words list\n",
      "[['root', 'tablet', 'park', 'horn', 'face', 'millionaire', 'phoenix', 'bed', 'moon'], ['revolution', 'platypus', 'mercury', 'stream', 'carrot', 'engine', 'agent', 'cold'], ['bell', 'whale', 'march', 'comic', 'spider', 'opera', 'parachute'], ['bear']]\n",
      "Giving hint...\n",
      "(6, ['arizona', 'kentucky', 'portland', 'rochester', 'cambodia', 'brighton', 'dubai'], [['phoenix', 'park', 'moon', 'face', 'root', 'millionaire'], ['phoenix', 'bed', 'park', 'moon', 'millionaire', 'root'], ['park', 'phoenix', 'root', 'bed', 'millionaire', 'tablet'], ['park', 'bed', 'millionaire', 'face', 'moon', 'phoenix'], ['moon', 'park', 'phoenix', 'bed', 'root', 'face'], ['park', 'phoenix', 'millionaire', 'moon', 'bed', 'face'], ['phoenix', 'park', 'millionaire', 'moon', 'face', 'bed']])\n"
     ]
    }
   ],
   "source": [
    "## Test Cell\n",
    "\n",
    "# similarity_matrix = pd.read_csv('../data/similarity_matrix.csv', index_col=0).drop_duplicates()\n",
    "# print(similarity_matrix.shape)\n",
    "\n",
    "# hint_words = load_hint_words()\n",
    "# game_words = load_codename_words()\n",
    "\n",
    "# board = get_example_board(game_words)\n",
    "# print(board)\n",
    "\n",
    "# print(\"Giving hint...\")\n",
    "# hint = hint_giver(similarity_matrix, board)\n",
    "# print(hint) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[are_similar] OUTPUT: happy and happier are similar: Lancaster Stemmer\n",
      "[are_similar] OUTPUT: clouds and cloudy are similar: longest common substring too long\n",
      "[are_similar] OUTPUT: trouble and troubling are similar: Porter Stemmer\n",
      "[are_similar] OUTPUT: troubling and trout are similar: longest common substring too long\n",
      "[are_similar] OUTPUT: nineteen and eighteen are similar: longest common substring too long\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Scratch Cell\n",
    "\n",
    "# are_similar(\"happy\", \"happier\")\n",
    "# are_similar(\"clouds\", \"cloudy\")\n",
    "# are_similar(\"trouble\", \"troubling\")\n",
    "# are_similar(\"troubling\", \"trout\")\n",
    "# are_similar(\"nineteen\", \"eighteen\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
